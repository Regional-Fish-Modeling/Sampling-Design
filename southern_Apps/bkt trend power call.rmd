---
title: "bkt power model fit to Southern Apps data"
author: "yk"
date: "January 29, 2016"
output: html_document
---

# 02/11/2016
# Power analysis for detecting a temporal trend in regional brook trout abundance
# Fit a model to southern Apps data compiled by THan Hitt
==================================================================================

## working directory & libraries
```{r working directory & libraries, warning=FALSE, message=FALSE}
setwd("D:/Kanno/bkt_sample_design/southern_Apps")
getwd()
library(reshape2); library(rjags); library(plyr); library(ggplot2)
library(knitr); library(arm); library(boot)
load.module("glm")
```

## Read in data from Than's data
```{r Read in data}
# Trout count data
load("Data_FishCountAr.RData")
# Imports pass-specific count data for each site and year

# Detection covriates data
load("Data_DetectionCovsStd.RData")
# Imports sampling day-of-year and precip in prior 7 days from DAYMET data (standardized)
```

## prep for JAGS
```{r prep for JAGS}
# data structure
nSites = dim(YOYFish)[1]
nYears = dim(YOYFish)[2]

# bundle data - testing YOY abundance
dat <- list(nSites=nSites, nYears=nYears, y=YOYFish,
            prcp7day=prcp7day.std, sampday=sampday.std)

# set initial values
init <- function() list(mu=runif(1,0,10), 
                        N=array(1000, dim=c(nSites, nYears)),
                        sd.slope=runif(1,0,5), sd.site=runif(1,0,5),
                        sd.year=runif(1,0,5), sigma=runif(1,0,5),
                        p.mean=runif(1,0,1), p.b=rnorm(1)) #, p.sigma=runif(1,0,0.1))

# parameters to monitor
pars <- c("mu","trend","sd.slope","sd.site","sd.year","sigma",
          "p.mean","p.b","p.sigma")
```

## model statement
```{r model, eval=FALSE}
# just paste the model from the r file for R Markdown to display the code

model{
  
  # Abundance model
  
  for(i in 1:nSites){
    for(j in 1:nYears){
      N[i,j] ~ dpois(lambda[i,j])
      log(lambda[i,j]) <- mu + (trend + slope.ran[i])*(j-1) + site.ran[i] + year.ran[j] + eps[i,j]
    }
  }
  
  ## priors
  mu ~ dnorm(0, 0.01)      # overall intercept
  trend ~ dnorm(0, 0.01)   # linear trend
  for(i in 1:nSites){
    slope.ran[i] ~ dnorm(0, tau.slope)  # random slope effects
  }
  sd.slope ~ dunif(0,5)
  tau.slope <- pow(sd.slope, -2)
  
  ######### Random walk on spatial variance
  # the first year estimates of spatial variability
  # sd.site[1] ~ dunif(0,5)
  # tau.site[1] <- 1/(sd.site[1]^2)
  # wn[1] <- 0  # white noise
  
  # estimating spatail variance as AR1 process
  # for(j in 2:nYears){
  #  tau.site[j] <- tau.site[j-1] + wn[j]
  #  wn[j] ~ dnorm(0,tau.wn)
  #}
  #tau.wn <- 1/(sd.wn^2)
  #sd.wn ~ dunif(0,5) # first order random walk model variance parameter 
  
  for(i in 1:nSites){
    site.ran[i] ~ dnorm(0,tau.site)     # random site effects
  }
  tau.site <- pow(sd.site, -2)
  sd.site ~ dunif(0,5)
  sd2.site <- pow(sd.site, 2)
  
  
  for (j in 1:nYears){
    year.ran[j] ~ dnorm(0, tau.year)  # Random year effect
  }
  tau.year <- pow(sd.year, -2) 
  sd.year ~ dunif(0,5)
  sd2.year <- pow(sd.year, 2)
  
  for(i in 1:nSites){
    for(j in 1:nYears){
      eps[i,j] ~ dnorm(0, tau)  # Over-dispersion
    }
  }
  tau <- pow(sigma, -2)
  sigma ~ dunif(0, 5)
  sigma2 <- pow(sigma, 2)
  
  # Detection model
  
  for(i in 1:nSites){
    for(j in 1:nYears){
      y[i,j,1] ~ dbin(p[i,j], N[i,j])
      y[i,j,2] ~ dbin(p[i,j], N[i,j]-y[i,j,1])
      y[i,j,3] ~ dbin(p[i,j], N[i,j]-y[i,j,1]-y[i,j,2])
      
      p[i,j] <- 1/(1 + exp(-lp.lim[i,j]))
      lp.lim[i,j] <- min(999, max(-999, lp[i,j]))
      lp[i,j] <- p.mu + p.b*sampday[i,j] + p.eps[i]
      # removed "prcp7day" for its small effect
    }
  }
  
  ## priors  
  p.mean ~ dunif(0,1)
  p.mu <- log(p.mean/(1-p.mean))
  p.b ~ dnorm(0, 0.37)
  
  for(i in 1:nSites){
    p.eps[i] ~ dnorm(0, p.tau)  # site-level variation
  }
  p.tau <- pow(p.sigma,-2)
  p.sigma ~ dunif(0,3)
  p.sigma2 <- pow(p.sigma, 2)
}  

```


## running JAGS
```{r running JAGS}
set.seed(123)
# burn-in
burnin <- jags.model(paste("bkt trend power model.r", sep=""),
                           dat, init, n.chains=3, n.adapt=50000)

# mcmc sample
out <- coda.samples(burnin, pars, n.iter=10000, thin=10)
summary(out)
plot(out)

# gelman r value
library(coda)
gelman.diag(out, multivariate=FALSE)
```
